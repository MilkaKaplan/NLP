{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SVB6AGwMl7a"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Model import: bart-large-mnli\n",
        "About the model: Yin et al. proposed a method for using pre-trained NLI models as a ready-made zero-shot sequence classifiers.\n",
        "The method works by posing the sequence to be classified as the NLI premise and to construct a hypothesis from each candidate label.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tfd4y_YDXeq"
      },
      "source": [
        "# **Imports:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MEndaf--hDY",
        "outputId": "2f847ebd-397b-4c84-e2f9-3340d19aeea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "3a0ab757113a4437bcecca9c2c252a95",
            "5b6837a847d0425ea959128475b90159",
            "7d2a2243628d42fe9b6cc1e79814fddc",
            "a326f81745a245b09b763c8367216e8f",
            "454105efe37444d9bd3ef025d9f42949",
            "455685eb9e114ab284e8380ba8a87382",
            "5578bae6008f44c2a22b111fdc364a95",
            "6b59157b18814f16aeadf1090f214da4",
            "4a83b3aa76854ba2bf0dcebb7802b3dd",
            "758d4b2c577d4bb8a0b90c2186cfd363",
            "c8abbfbc2641433e9660c5bef428d62d",
            "cf6affb13ca94469a95119e47011f75f",
            "b9fca15ad3e54bf4abdc450e31b62c6f",
            "3564f14cb7964ec686c31ea3689c9d58",
            "2ce1596bc4894e3b821046335be947a0",
            "8050ae03819146e18c395ba7a9d982ac",
            "326c92a200e146829f71d75430918628",
            "474f8003d6b54c2e84a4bd1b8948220f",
            "331a34533bb64b1681399a16b318c036",
            "7a96796e1f154b60bdc5d59674bc0f72",
            "ca51ad1592a44c90b44a6a063745973e",
            "d301acb6bb134cba8f0db6042f332899",
            "04b4e88263f6447a8c24fe920e0ed68f",
            "a48a979b59b94abda8ca98a44ace680b",
            "7d49950a3ba0489b9ca2c0c17b8ce2d0",
            "4b315c1601fd4d95bd90d1e96d3e5425",
            "febbdcdb120b49ada5fc503f189b1963",
            "c56618839b5c429cbbb965eab7757bff",
            "ceb9ad208b744b33a6db1d5e0db41e9e",
            "79eaaae43eb54be3b48fecd90a9c7fb9",
            "2f68bc99b5014190af749be1a3b8a6e9",
            "b80df99d562c414395b80c57070542b3",
            "660cd39bf74b41908b2e87bdd6bf70c1",
            "b44c60320ef6436a9e204fb3d5afabe6",
            "3cb8d54c4f2f4d079341d6a4e37fdf14",
            "0f7dbdbab7644630a7054764fcb9d85a",
            "15707b460603465cb9f93c2fda7b1153",
            "63cd4bb8d3d540939048d8d0922b93ed",
            "55f3dea3e05d40c498601e815ce1abff",
            "b6100c375f4a45659c88b7990b515122",
            "de6a9d8007254312a1946d18bed656fb",
            "fc3d3d2f6cf04668aed4ae783b66b361",
            "5e78933958134537be863d6f92a25547",
            "df9ca1be1fbf4863b3466b96f2486d60",
            "1c9f2554ad3b4b1aa7ea2afb04212468",
            "29304706a6914a8c99d903ad3e491744",
            "9c7c3b0327d34054983711b71b3c011d",
            "d633c8ef7ef246898df42868843fea69",
            "df482406f4b947dbb8b1d77323956eb3",
            "5a5ebe4abbfe4391ab50d9b30c19cb3d",
            "c9673d71f50943f7968aa7c959daa2b1",
            "a0fae9aa257c410388366b9fa1598539",
            "07706bf4284b4cacae51f5e5003a455d",
            "37ebe9aa8aa44e28ad6b9d48ddb5e78f",
            "69909eb29dc045beb36105246e8a5bd6",
            "427fed2d4cf44768a14b633941550e60",
            "8e65e33104494afd9300fda2c7925d1d",
            "2e1eca7439874aaa91545d9aa490bb11",
            "7bd035955fa143208ffaff7bff1f5a74",
            "55ef211e72934e1f9b95275acaf683c1",
            "6f739c9c3c564e25a8dffe1097108cca",
            "2ce6c08f81174cd69fddd3dd286be267",
            "925562651bb34946b133284ca993bdf9",
            "099fcabf3d294d82a9e6b75a845aeb31",
            "bbabffd01116488bbee518ac2405d382",
            "3a2163fdbdc44b82830fdc4cbb70774d"
          ],
          "height": 663
        },
        "id": "F57JINYRMF-8",
        "outputId": "0b9ea4da-33eb-4ed3-91c4-6f6ed21bfe69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a0ab757113a4437bcecca9c2c252a95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf6affb13ca94469a95119e47011f75f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04b4e88263f6447a8c24fe920e0ed68f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b44c60320ef6436a9e204fb3d5afabe6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c9f2554ad3b4b1aa7ea2afb04212468"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "427fed2d4cf44768a14b633941550e60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "\n",
        "import json\n",
        "from google.colab import drive\n",
        "from transformers import pipeline\n",
        "import os\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "from transformers import pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\",\n",
        "                      model=\"facebook/bart-large-mnli\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pd-Gq9zhG_f"
      },
      "source": [
        "# **For a single file:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JCLNyzJYKDg"
      },
      "outputs": [],
      "source": [
        "# File paths\n",
        "#input_file_path = '/content/drive/Shareddrives/facebook_model/tets.json'\n",
        "#output_directory = '/content/drive/Shareddrives/facebook_model/results'\n",
        "#output_file_path = os.path.join(output_directory, 'results.json')\n",
        "\n",
        "# Ensure the output directory exists\n",
        "#os.makedirs(output_directory, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpW5uguRYK2k"
      },
      "outputs": [],
      "source": [
        "# Load the JSON file into a dictionary\n",
        "#with open(input_file_path, 'r') as file:\n",
        " #   data = json.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-uRJ5v6YR07"
      },
      "outputs": [],
      "source": [
        "# Initialize the classifier\n",
        "#classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdJRyt0oYVbN"
      },
      "outputs": [],
      "source": [
        "# Extract sentences related to the petitioner\n",
        "#petitioner_sentences = data.get(\"Barbara D. Underwood\", [])\n",
        "\n",
        "# Define candidate labels\n",
        "#candidate_labels = ['Confidence', 'Hesitation', 'Anger', 'Neutrality', 'Defensiveness', 'Frustration']\n",
        "\n",
        "# Data structure to save results\n",
        "#results = []\n",
        "\n",
        "# Classify each sentence and save the results\n",
        "#for sentence in petitioner_sentences:\n",
        " #   result = classifier(sentence, candidate_labels, multi_label=True)\n",
        "  #  results.append({\n",
        "   #     \"sentence\": sentence,\n",
        "    #    \"classification\": {label: round(score, 4) for label, score in zip(result['labels'], result['scores'])}\n",
        "    #})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spOOQeEoYYVj"
      },
      "outputs": [],
      "source": [
        "# Save the results to the specified file\n",
        "#with open(output_file_path, 'w') as output_file:\n",
        " #   json.dump(results, output_file, indent=4)\n",
        "\n",
        "# Print completion message\n",
        "#print(f\"Classification results saved to {output_file_path}\")\n",
        "\n",
        "# Print completion message with the number of extracted sentences\n",
        "#num_sentences = len(petitioner_sentences)\n",
        "#print(f\"{num_sentences} sentences were extracted and classified.\")\n",
        "#print(f\"Classification results saved to {output_file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCmvzp4dhb2Z"
      },
      "source": [
        "# **Multiple files:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rej6aQKbr3q"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8113SNGSjYQB"
      },
      "outputs": [],
      "source": [
        "# Directories\n",
        "input_directory = '/content/drive/Shareddrives/facebook_model/ravit'\n",
        "output_directory = '/content/drive/Shareddrives/facebook_model/results_ravit'\n",
        "\n",
        "output_directory = '/content/drive/Shareddrives/facebook_model/results_ravit'\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(output_directory, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoCEZvkYjcas",
        "outputId": "bbf8e5da-b0c1-4f0f-9eda-933212cd40f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# Initialize the classifier\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Define candidate labels\n",
        "candidate_labels = ['Confidence', 'Hesitation', 'Anger', 'Neutrality', 'Defensiveness', 'Frustration']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz3Zr2iokQWb",
        "outputId": "da2dffd1-a252-4097-9d86-cca74092fa69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in fb_contin_all_years_1.33 directory:\n",
            "['עותק של עותק של argument_08_6925.json']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if os.path.exists(input_directory):\n",
        "    print(\"Files in fb_contin_all_years_1.33 directory:\")\n",
        "    print(os.listdir(input_directory))\n",
        "else:\n",
        "    print(\"The specified directory does not exist.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12WpTtwEf9Rx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EToPWnwbjeKn"
      },
      "outputs": [],
      "source": [
        "def process_file(input_file_path, output_file_path, classifier, candidate_labels):\n",
        "    try:\n",
        "        # Load the JSON file\n",
        "        with open(input_file_path, 'r') as file:\n",
        "            data = json.load(file)\n",
        "\n",
        "        # Extract the petitioner's name\n",
        "        petitioner_name = data.get(\"petitioner advocate\")\n",
        "        if not petitioner_name:\n",
        "            print(f\"No 'petitioner advocate' key found in {input_file_path}. Skipping file.\")\n",
        "            return None\n",
        "\n",
        "        # Extract sentences related to the petitioner\n",
        "        petitioner_key = \"petitioner advocate transcript\"\n",
        "        petitioner_sentences = data.get(petitioner_key, [])\n",
        "        if not petitioner_sentences:\n",
        "            print(f\"No sentences found for petitioner '{petitioner_name}' in {input_file_path}. Skipping file.\")\n",
        "            return None\n",
        "\n",
        "        # Classify each sentence\n",
        "        results = []\n",
        "        for sentence in petitioner_sentences:\n",
        "            result = classifier(sentence, candidate_labels, multi_label=True)\n",
        "            results.append({\n",
        "                \"sentence\": sentence,\n",
        "                \"classification\": {label: round(score, 4) for label, score in zip(result['labels'], result['scores'])}\n",
        "            })\n",
        "\n",
        "        # Save the results to the output file\n",
        "        with open(output_file_path, 'w') as output_file:\n",
        "            json.dump(results, output_file, indent=4)\n",
        "\n",
        "        print(f\"Processed {len(petitioner_sentences)} sentences from {os.path.basename(input_file_path)}.\")\n",
        "        print(f\"Results saved to {output_file_path}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {input_file_path}: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZhChOmejgKH",
        "outputId": "55b47cff-8ab5-45b5-9b62-3891be6ce43f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 129 sentences from עותק של עותק של argument_08_6925.json.\n",
            "Results saved to /content/drive/Shareddrives/facebook_model/results_ravit/עותק של עותק של argument_08_6925_result.json.\n"
          ]
        }
      ],
      "source": [
        "# Process each file in the input directory\n",
        "for filename in os.listdir(input_directory):\n",
        "    if filename.endswith('.json'):  # Ensure only JSON files are processed\n",
        "        input_file_path = os.path.join(input_directory, filename)\n",
        "        output_file_path = os.path.join(output_directory, f\"{os.path.splitext(filename)[0]}_result.json\")\n",
        "\n",
        "\n",
        "        # Process the file\n",
        "        process_file(input_file_path, output_file_path, classifier, candidate_labels)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9Tfd4y_YDXeq",
        "9Pd-Gq9zhG_f"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
    
  "nbformat": 4,
  "nbformat_minor": 0
}